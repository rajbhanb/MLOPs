# -*- coding: utf-8 -*-
"""Assignment 1 - Data Versioning and Differential Privacy Bimal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TTJ7W3mNbPyppMkpZH8mlkljqy_hmVtY

# **Using lakeFS**
"""

#!pip install s3fs
import os
os.environ['AWS_ACCESS_KEY_ID'] = 'removed key to protect privacy'
os.environ['AWS_SECRET_ACCESS_KEY'] = 'removed key to protect privacy'

#Loading inital raw data from lakeFS cloud
import pandas as pd
"""
Go to your LakeFS Cloud repository.
Navigate to the file: main/athletes.csv.
Click the setting by the file name.
Click Download or Copy Pre-signed URL.
Use the URL in Colab below
"""


v2 = pd.read_csv('https://bimal-athletesdataset1.s3.us-east-1.amazonaws.com/data/g5d7m5gmmajs73fpmd1g/d3q8l4ommajs73fpmd2g?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVRT4YC5XXZLASLHV%2F20251023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251023T010633Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dathletes.csv&x-id=GetObject&X-Amz-Signature=fb005efb39a285ea8279bb0cefbada0990886c5a0b4f6322d39494a0ef27eeeb')

pd.set_option('display.max_columns', None)
display(v2)

"""# **Clean Dataset**"""

import numpy as np

# Remove missing values and not relevant columns
v2 = v2.dropna(subset=['region','age','weight','height','howlong','gender','eat', \
                               'train','background','experience','schedule','howlong', \
                               'deadlift','candj','snatch','backsq','experience',\
                               'background','schedule','howlong'])

v2 = v2.drop(columns=['affiliate','team','name','athlete_id','fran','helen','grace',\
                              'filthy50','fgonebad','run400','run5k','pullups','train'])

# Remove Outliers
v2 = v2[v2['weight'] < 1500]  # Remove unrealistic weights
v2 = v2[v2['gender'] != '--']  # Remove invalid gender entries
v2 = v2[v2['age'] >= 18]  # Keep only adults

# Height bounds (inches)
v2 = v2[(v2['height'] < 96) & (v2['height'] > 48)]

# Deadlift bounds (gender-specific)
v2 = v2[
    (v2['deadlift'] > 0) &
    (
        ((v2['gender'] == 'Male') & (v2['deadlift'] <= 1105)) |
        ((v2['gender'] == 'Female') & (v2['deadlift'] <= 636))
    )
]

# Clean and Clean & Jerk bounds
v2 = v2[(v2['candj'] > 0) & (v2['candj'] <= 395)]
v2 = v2[(v2['snatch'] > 0) & (v2['snatch'] <= 496)]
v2 = v2[(v2['backsq'] > 0) & (v2['backsq'] <= 1069)]

# Clean Survey Data: Replace "Decline to answer|" with NaN
decline_dict = {'Decline to answer|': np.nan}
v2 = v2.replace(decline_dict)

# Drop rows with missing values in critical columns
v2 = v2.dropna(subset=['background', 'experience', 'schedule', 'howlong', 'eat'])

pd.set_option('display.max_columns', None)
display(v2)

# After cleaning the dataset, save v2 as a CSV
v2.to_csv('/content/drive/MyDrive/MLOPS/athletes_v2.csv', index=False)

#Accessing v2 after commiting to lakefs cloud
v2 = pd.read_csv('https://bimal-athletesdataset1.s3.us-east-1.amazonaws.com/data/g5d6ikrj8rvc73fsm2tg/d3q9jbbj8rvc73fsm2u0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVRT4YC5XXZLASLHV%2F20251019%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251019T080104Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dathletes_v2.csv&x-id=GetObject&X-Amz-Signature=939c62f2b37d7dc1c373a0cd5049da4108bb181d2e27da72d9838b8177987318')
pd.set_option('display.max_columns', None)
display(v2)

v1 = pd.read_csv('https://bimal-athletesdataset1.s3.us-east-1.amazonaws.com/data/g5d7m5gmmajs73fpmd1g/d3q8l4ommajs73fpmd2g?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVRT4YC5XXZLASLHV%2F20251019%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251019T080355Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dathletes.csv&x-id=GetObject&X-Amz-Signature=3584f008146d91f59ece502cb2ec359c79be035f979b1e58acb56cb5be04b70f')
pd.set_option('display.max_columns', None)
display(v1)

#Drop all non-numeric columns for v2
v2_numeric = v2.select_dtypes(include='number')

# Display the resulting DataFrame
print(v2_numeric.head())

#Drop all non-numeric columns for v1
v1_numeric = v1.select_dtypes(include='number')

# Display the resulting DataFrame
print(v1_numeric.head())

# After cleaning the dataset, save v2 as a CSV
v2_numeric.to_csv('/content/drive/MyDrive/MLOPS/athletes_numeric_v2.csv', index=False)

# After cleaning the dataset, save v2 as a CSV
v1_numeric.to_csv('/content/drive/MyDrive/MLOPS/athletes_numeric_v1.csv', index=False)

#Accessing v1 after commiting to lakefs cloud
v1 = pd.read_csv('https://bimal-athletesdataset1.s3.us-east-1.amazonaws.com/data/g5ao138mmajs73fpmd40/d3socqgmmajs73fpmd70?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVRT4YC5XXZLASLHV%2F20251023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251023T070452Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dathletes_numeric_v1.csv&x-id=GetObject&X-Amz-Signature=da44366f017427f5d9dffb03bfd1de0892dece9081d348e864b1156e12de9329')
pd.set_option('display.max_columns', None)
display(v1)

"""# **5.Run EDA (exploratory data analysis) of the dataset v1.**"""

display(v1.isnull().sum())

def missing_statistics(df):
    '''
        Calculates missing value statistics for a given dataframe and
        returns a dataframe containing number of missing values per column
        and the percentage of values missing per column.
        arguments:
            df: the dataframe for which missing values need to be calculated.
    '''
    missing_stats = df.isnull().sum().to_frame()
    missing_stats.columns = ['num_missing']
    missing_stats['pct_missing'] = np.round(100 * (missing_stats['num_missing'] / df.shape[0]))
    missing_stats.sort_values(by='num_missing', ascending=False, inplace=True)

    return missing_stats

# Calculate and display missing value statistics
missing_stats_v1 = missing_statistics(v1)
print(missing_stats_v1)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Select only numeric columns for correlation
numeric_cols = v1.select_dtypes(include=['int64', 'float64']).columns
corr_matrix = v1[numeric_cols].corr(method='spearman')

# Create mask for upper triangle
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

# Plot correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix,
            mask=mask,
            annot=True,
            fmt='.2f',
            cmap='coolwarm',
            center=0,
            square=True,
            linewidths=.5,
            cbar_kws={'shrink': .5})

plt.title('Spearman Correlation Matrix (Numeric Features Only)', pad=20)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
# Calculate frequency of each category in 'howlong'
howlong_freq = v1['age'].value_counts()

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))  # Adjust figure size if needed
howlong_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Frequency of "Age" Responses (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('How Long', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)  # Add grid lines for readability

# Add frequency numbers above each bar
for index, value in enumerate(howlong_freq.values):
    plt.text(value + 0.5,  # x position (value + small offset)
             index - 0.1,  # y position (slightly above the bar)
             str(value),   # text to display
             fontsize=10,
             va='center')

# Show the plot
plt.tight_layout()  # Prevent label cutoff
plt.show()

import pandas as pd
import matplotlib.pyplot as plt



# Calculate frequency of each category in 'height' and select top 10
height_freq = v1['height'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "height" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt



# Calculate frequency of each category in 'height' and select top 10
height_freq = v1['candj'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "candj" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt



# Calculate frequency of each category in 'height' and select top 10
height_freq = v1['snatch'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "snatch" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Plot distributions for v1
v1['deadlift'].hist(bins=20)
plt.title('Deadlift Distribution (v1)')
plt.show()

"""# **3.For both versions calculate deadlift and divide dataset into train and test, keeping the same split ratio.**"""

from sklearn.model_selection import train_test_split

# Drop rows where 'deadlift' is missing
v1 = v1.dropna(subset=['deadlift'])
v2 = v2.dropna(subset=['deadlift'])

# Split v1
X_train_v1, X_test_v1, y_train_v1, y_test_v1 = train_test_split(
    v1.drop(columns=['deadlift']), v1['deadlift'], test_size=0.2, random_state=42
)

# Split v2
X_train_v2, X_test_v2, y_train_v2, y_test_v2 = train_test_split(
    v2.drop(columns=['deadlift']), v2['deadlift'], test_size=0.2, random_state=42
)

"""
# **6.Build Baseline Model (v1)**

"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Train model on v1
model_v1 = RandomForestRegressor(random_state=42)
model_v1.fit(X_train_v1, y_train_v1)

"""# **7.Run metrics for this model.**"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Predict and evaluate
y_pred_v1 = model_v1.predict(X_test_v1)
rmse_v1 = np.sqrt(mean_squared_error(y_test_v1, y_pred_v1))
r2_v1 = r2_score(y_test_v1, y_pred_v1)

print("v1 RMSE:", rmse_v1)
print("v1 R²:", r2_v1)

"""# **8.Update the dataset version to go to dataset v2 without changing anything else in the training code.**"""

#Accessing v2 after commiting to lakefs cloud
import pandas as pd
v2 = pd.read_csv('https://bimal-athletesdataset1.s3.us-east-1.amazonaws.com/data/g5anpijj8rvc73fsm31g/d3socdjj8rvc73fsm320?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVRT4YC5XXZLASLHV%2F20251023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251023T070418Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dathletes_numeric_v2.csv&x-id=GetObject&X-Amz-Signature=2adc75eb55473d5a630e9ce8507932c2efe91216efa977de9def3330b8159f79')
pd.set_option('display.max_columns', None)
display(v2)

"""# **9.Run EDA (exploratory data analysis) of the dataset v2.**"""

display(v2.isnull().sum())

# Calculate and display missing value statistics
missing_stats_v2 = missing_statistics(v2)
print(missing_stats_v2)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Select only numeric columns for correlation
numeric_cols = v1.select_dtypes(include=['int64', 'float64']).columns
corr_matrix = v1[numeric_cols].corr(method='spearman')

# Create mask for upper triangle
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

# Plot correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix,
            mask=mask,
            annot=True,
            fmt='.2f',
            cmap='coolwarm',
            center=0,
            square=True,
            linewidths=.5,
            cbar_kws={'shrink': .5})

plt.title('Spearman Correlation Matrix (Numeric Features Only)', pad=20)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
# Calculate frequency of each category in 'howlong'
howlong_freq = v2['age'].value_counts()

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))  # Adjust figure size if needed
howlong_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Frequency of "Age" Responses (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('How Long', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)  # Add grid lines for readability

# Add frequency numbers above each bar
for index, value in enumerate(howlong_freq.values):
    plt.text(value + 0.5,  # x position (value + small offset)
             index - 0.1,  # y position (slightly above the bar)
             str(value),   # text to display
             fontsize=10,
             va='center')

# Show the plot
plt.tight_layout()  # Prevent label cutoff
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
# Calculate frequency of each category in 'howlong'
howlong_freq = v2['height'].value_counts()

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))  # Adjust figure size if needed
howlong_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Frequency of "height" Responses (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('How Long', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)  # Add grid lines for readability

# Add frequency numbers above each bar
for index, value in enumerate(howlong_freq.values):
    plt.text(value + 0.5,  # x position (value + small offset)
             index - 0.1,  # y position (slightly above the bar)
             str(value),   # text to display
             fontsize=10,
             va='center')

# Show the plot
plt.tight_layout()  # Prevent label cutoff
plt.show()

import pandas as pd
import matplotlib.pyplot as plt


# Calculate frequency of each category in 'height' and select top 10
height_freq = v2['candj'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "candj" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt


# Calculate frequency of each category in 'height' and select top 10
height_freq = v2['snatch'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "snatch" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Plot distributions for v1
v2['deadlift'].hist(bins=20)
plt.title('Deadlift Distribution (v1)')
plt.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Train model on v2
model_v2 = RandomForestRegressor(random_state=42)
model_v2.fit(X_train_v2, y_train_v2)

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Predict and evaluate
y_pred_v2 = model_v2.predict(X_test_v2)
rmse_v2 = np.sqrt(mean_squared_error(y_test_v2, y_pred_v2))
r2_v2 = r2_score(y_test_v2, y_pred_v2)

print("v2 RMSE:", rmse_v2)
print("v2 R²:", r2_v2)

"""# **12.Compare and comment on the accuracy/metrics of the models using v1 and v2.**

RMSE (Root Mean Squared Error) measures the average prediction error. A lower RMSE indicates better accuracy.


* v2 has a significantly lower RMSE, meaning its predictions are much closer to actual values.


* This suggests that the data cleaning and outlier removal in v2 greatly improved model precision.



R² Score indicates how well the model explains the variance in the target variable.


* v1 has a higher R², meaning it explains more variance, but this could be due to overfitting on noisy or inconsistent data.


* v2’s slightly lower R² is still strong and reflects a more generalizable model trained on cleaner data.

# **13. Use Opacus library with the dataset v2 and calculate the metrics for the new differential privacy model.**
"""

!pip install opacus torch torchvision

from sklearn.preprocessing import StandardScaler
import torch
from torch.utils.data import DataLoader, TensorDataset

# Standardize features for v2
scaler = StandardScaler()
X_train_v2_scaled = scaler.fit_transform(X_train_v2)
X_test_v2_scaled = scaler.transform(X_test_v2)

# Convert to PyTorch tensors
X_train_v2_tensor = torch.FloatTensor(X_train_v2_scaled)
y_train_v2_tensor = torch.FloatTensor(y_train_v2.values).view(-1, 1)
X_test_v2_tensor = torch.FloatTensor(X_test_v2_scaled)
y_test_v2_tensor = torch.FloatTensor(y_test_v2.values).view(-1, 1)

# Create DataLoader for v2
train_dataset_v2 = TensorDataset(X_train_v2_tensor, y_train_v2_tensor)
train_loader_v2 = DataLoader(train_dataset_v2, batch_size=32, shuffle=True)

"""**Define the Shallow Neural Network**"""

import torch.nn as nn

class ShallowNN(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 16)  # First hidden layer
        self.fc2 = nn.Linear(16, 8)          # Second hidden layer
        self.fc3 = nn.Linear(8, 1)           # Output layer
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        return self.fc3(x)

# Initialize model
input_dim = X_train_v2.shape[1]
model = ShallowNN(input_dim)

"""**Set Up DP Training with Opacus**"""

from opacus import PrivacyEngine
from torch.optim import Adam

# Define optimizer and loss
optimizer = Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# Enable DP training
privacy_engine = PrivacyEngine()

model, optimizer, train_loader_v2 = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=train_loader_v2,
    max_grad_norm=1.0,      # Gradient clipping
    noise_multiplier=0.5    # Noise for privacy
)

"""#  **14. Compute the DP ε (differential privacy budget)**


*   ε (epsilon) quantifies the privacy loss during training.

*   A smaller ε means stronger privacy, but potentially lower model accuracy.

*   A larger ε means weaker privacy, but potentially better model performance.
"""

# Training loop
epochs = 50
for epoch in range(epochs):
    model.train()
    for batch_X, batch_y in train_loader_v2:
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()

    # Print progress every 10 epochs
    if epoch % 10 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# Get privacy budget
epsilon = privacy_engine.accountant.get_epsilon(delta=1e-5)
print(f"Final Privacy Budget (ε): {epsilon:.2f}")

"""**Evaluate the Model**"""

from sklearn.metrics import mean_squared_error, r2_score

# Evaluate on test data
model.eval()
with torch.no_grad():
    y_pred_tensor = model(X_test_v2_tensor)
    y_pred = y_pred_tensor.numpy()

# Calculate metrics
rmse_dp = np.sqrt(mean_squared_error(y_test_v2, y_pred))
r2_dp = r2_score(y_test_v2, y_pred)

print(f"DP Shallow NN RMSE: {rmse_dp:.4f}")
print(f"DP Shallow NN R²: {r2_dp:.4f}")

"""# **Compare and comment on the accuracy/metrics of the non-DP and DP models using dataset v2**

The DP model introduces noise during training to protect individual data points.
Despite this, the performance degradation is minimal:


*   RMSE increased by only 0.14 units.

*   R² dropped by just 0.0011.

This shows that the DP model maintains strong predictive power while offering privacy guarantees.

Both models perform very well.The non-DP model is slightly more accurate, but the DP model is nearly as good and provides privacy protection. If privacy is a concern (e.g., sensitive athlete data), the DP model is a highly viable choice with minimal trade-off in accuracy.
"""

# Reset model and optimizer for non-DP training
model_non_dp = ShallowNN(input_dim)
optimizer_non_dp = Adam(model_non_dp.parameters(), lr=0.001)

# Train without DP
for epoch in range(epochs):
    model_non_dp.train()
    for batch_X, batch_y in train_loader_v2:
        optimizer_non_dp.zero_grad()
        outputs = model_non_dp(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer_non_dp.step()

# Evaluate non-DP model
model_non_dp.eval()
with torch.no_grad():
    y_pred_non_dp = model_non_dp(X_test_v2_tensor).numpy()

rmse_non_dp = np.sqrt(mean_squared_error(y_test_v2, y_pred_non_dp))
r2_non_dp = r2_score(y_test_v2, y_pred_non_dp)

print(f"Non-DP Shallow NN RMSE: {rmse_non_dp:.4f}")
print(f"Non-DP Shallow NN R²: {r2_non_dp:.4f}")

import matplotlib.pyplot as plt
import numpy as np

# Metrics for comparison
metrics = {
    'Model': ['Non-DP Shallow NN', 'DP Shallow NN'],
    'RMSE': [rmse_non_dp, rmse_dp],
    'R²': [r2_non_dp, r2_dp]
}

x = np.arange(len(metrics['Model']))
width = 0.35

fig, ax1 = plt.subplots(figsize=(10, 6))

# Plot RMSE
bars1 = ax1.bar(x - width/2, metrics['RMSE'], width, label='RMSE', color='tab:blue')
ax1.set_ylabel('RMSE', color='tab:blue')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Plot R²
ax2 = ax1.twinx()
bars2 = ax2.bar(x + width/2, metrics['R²'], width, label='R²', color='tab:orange')
ax2.set_ylabel('R²', color='tab:orange')
ax2.tick_params(axis='y', labelcolor='tab:orange')

ax1.set_xticks(x)
ax1.set_xticklabels(metrics['Model'])
plt.title('DP vs Non-DP Shallow Neural Network Performance on v2 Dataset')
fig.legend(loc="upper right", bbox_to_anchor=(1, 1), bbox_transform=ax1.transAxes)
plt.tight_layout()
plt.show()

# Get feature importance by looking at first layer weights
weights = model.fc1.weight.detach().numpy().mean(axis=0)
feature_importance = pd.DataFrame({
    'Feature': X_train_v2.columns,
    'Importance': np.abs(weights)
}).sort_values('Importance', ascending=False)

print("\nFeature Importance:")
print(feature_importance)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['Feature'], feature_importance['Importance'])
plt.title('Feature Importance from First Layer Weights')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

"""# **Weights & Biases**"""

import wandb
wandb.login()
#click on your name on top right and click on API key : 

"""# **4.Use tool to version the dataset**

Since the dataset is already cleaned above, we will version the 2 datasets right away.
"""

with wandb.init(project="athletes-dataset", job_type="data-versioning") as run:
    artifact = wandb.Artifact('dataset_v1_numeric', type='dataset')
    artifact.add_file('/content/drive/MyDrive/MLOPS/athletes_v1.csv')
    run.log_artifact(artifact)

with wandb.init(project="athletes-dataset", job_type="data-versioning") as run:
    artifact = wandb.Artifact('dataset_v2', type='dataset')
    artifact.add_file('/content/drive/MyDrive/MLOPS/athletes_v2.csv')
    run.log_artifact(artifact)

"""**Pulling V1 and V2 dataset using weight and biases**"""

import pandas as pd
import wandb

# Initialize W&B API
api = wandb.Api()

# Fetch the latest version of dataset_v1
artifact_v1 = api.artifact('uchicago-bimal/athletes-dataset/dataset_v1:latest')

# Download the artifact
artifact_v1_dir = artifact_v1.download()

# Load the dataset into a DataFrame
v1 = pd.read_csv(f"{artifact_v1_dir}/athletes_v1.csv")

# Fetch the latest version of dataset_v2
artifact_v2 = api.artifact('uchicago-bimal/athletes-dataset/dataset_v2:latest')

# Download the artifact
artifact_v2_dir = artifact_v2.download()

# Load the dataset into a DataFrame
v2 = pd.read_csv(f"{artifact_v2_dir}/athletes_v2.csv")

"""# **5.Run EDA (exploratory data analysis) of the dataset v1.**"""

display(v1.isnull().sum())

def missing_statistics(df):
    '''
        Calculates missing value statistics for a given dataframe and
        returns a dataframe containing number of missing values per column
        and the percentage of values missing per column.
        arguments:
            df: the dataframe for which missing values need to be calculated.
    '''
    missing_stats = df.isnull().sum().to_frame()
    missing_stats.columns = ['num_missing']
    missing_stats['pct_missing'] = np.round(100 * (missing_stats['num_missing'] / df.shape[0]))
    missing_stats.sort_values(by='num_missing', ascending=False, inplace=True)

    return missing_stats

# Calculate and display missing value statistics
missing_stats_v1 = missing_statistics(v1)
print(missing_stats_v1)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Select only numeric columns for correlation
numeric_cols = v1.select_dtypes(include=['int64', 'float64']).columns
corr_matrix = v1[numeric_cols].corr(method='spearman')

# Create mask for upper triangle
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

# Plot correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix,
            mask=mask,
            annot=True,
            fmt='.2f',
            cmap='coolwarm',
            center=0,
            square=True,
            linewidths=.5,
            cbar_kws={'shrink': .5})

plt.title('Spearman Correlation Matrix (Numeric Features Only)', pad=20)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
# Calculate frequency of each category in 'howlong'
howlong_freq = v1['age'].value_counts()

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))  # Adjust figure size if needed
howlong_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Frequency of "Age" Responses (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('How Long', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)  # Add grid lines for readability

# Add frequency numbers above each bar
for index, value in enumerate(howlong_freq.values):
    plt.text(value + 0.5,  # x position (value + small offset)
             index - 0.1,  # y position (slightly above the bar)
             str(value),   # text to display
             fontsize=10,
             va='center')

# Show the plot
plt.tight_layout()  # Prevent label cutoff
plt.show()

import pandas as pd
import matplotlib.pyplot as plt



# Calculate frequency of each category in 'height' and select top 10
height_freq = v1['height'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "height" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt



# Calculate frequency of each category in 'height' and select top 10
height_freq = v1['candj'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "candj" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt



# Calculate frequency of each category in 'height' and select top 10
height_freq = v1['snatch'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "snatch" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Plot distributions for v1
v1['deadlift'].hist(bins=20)
plt.title('Deadlift Distribution (v1)')
plt.show()

"""# **3.For both versions calculate deadlift and divide dataset into train and test, keeping the same split ratio.**"""

from sklearn.model_selection import train_test_split

# Drop rows where 'deadlift' is missing
v1 = v1.dropna(subset=['deadlift'])
v2 = v2.dropna(subset=['deadlift'])

# Split v1
X_train_v1, X_test_v1, y_train_v1, y_test_v1 = train_test_split(
    v1.drop(columns=['deadlift']), v1['deadlift'], test_size=0.2, random_state=42
)

# Split v2
X_train_v2, X_test_v2, y_train_v2, y_test_v2 = train_test_split(
    v2.drop(columns=['deadlift']), v2['deadlift'], test_size=0.2, random_state=42
)

"""
# **6.Build Baseline Model (v1)**

"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Train model on v1
model_v1 = RandomForestRegressor(random_state=42)
model_v1.fit(X_train_v1, y_train_v1)

"""# **7.Run metrics for this model.**"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Predict and evaluate
y_pred_v1 = model_v1.predict(X_test_v1)
rmse_v1 = np.sqrt(mean_squared_error(y_test_v1, y_pred_v1))
r2_v1 = r2_score(y_test_v1, y_pred_v1)

print("v1 RMSE:", rmse_v1)
print("v1 R²:", r2_v1)

"""# **8.Update the dataset version to go to dataset v2 without changing anything else in the training code.**"""

#Accessing v2 after commiting to lakefs cloud
import pandas as pd
v2 = pd.read_csv('https://bimal-athletesdataset1.s3.us-east-1.amazonaws.com/data/g5anpijj8rvc73fsm31g/d3socdjj8rvc73fsm320?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVRT4YC5XXZLASLHV%2F20251023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251023T070418Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dathletes_numeric_v2.csv&x-id=GetObject&X-Amz-Signature=2adc75eb55473d5a630e9ce8507932c2efe91216efa977de9def3330b8159f79')
pd.set_option('display.max_columns', None)
display(v2)

"""# **9.Run EDA (exploratory data analysis) of the dataset v2.**"""

display(v2.isnull().sum())

# Calculate and display missing value statistics
missing_stats_v2 = missing_statistics(v2)
print(missing_stats_v2)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Select only numeric columns for correlation
numeric_cols = v1.select_dtypes(include=['int64', 'float64']).columns
corr_matrix = v1[numeric_cols].corr(method='spearman')

# Create mask for upper triangle
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

# Plot correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix,
            mask=mask,
            annot=True,
            fmt='.2f',
            cmap='coolwarm',
            center=0,
            square=True,
            linewidths=.5,
            cbar_kws={'shrink': .5})

plt.title('Spearman Correlation Matrix (Numeric Features Only)', pad=20)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
# Calculate frequency of each category in 'howlong'
howlong_freq = v2['age'].value_counts()

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))  # Adjust figure size if needed
howlong_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Frequency of "Age" Responses (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('How Long', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)  # Add grid lines for readability

# Add frequency numbers above each bar
for index, value in enumerate(howlong_freq.values):
    plt.text(value + 0.5,  # x position (value + small offset)
             index - 0.1,  # y position (slightly above the bar)
             str(value),   # text to display
             fontsize=10,
             va='center')

# Show the plot
plt.tight_layout()  # Prevent label cutoff
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
# Calculate frequency of each category in 'howlong'
howlong_freq = v2['height'].value_counts()

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))  # Adjust figure size if needed
howlong_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Frequency of "height" Responses (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('How Long', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)  # Add grid lines for readability

# Add frequency numbers above each bar
for index, value in enumerate(howlong_freq.values):
    plt.text(value + 0.5,  # x position (value + small offset)
             index - 0.1,  # y position (slightly above the bar)
             str(value),   # text to display
             fontsize=10,
             va='center')

# Show the plot
plt.tight_layout()  # Prevent label cutoff
plt.show()

import pandas as pd
import matplotlib.pyplot as plt


# Calculate frequency of each category in 'height' and select top 10
height_freq = v2['candj'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "candj" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt


# Calculate frequency of each category in 'height' and select top 10
height_freq = v2['snatch'].value_counts().head(10)

# Create a horizontal bar graph
plt.figure(figsize=(10, 6))
height_freq.plot(kind='barh', color='skyblue')

# Customize the plot
plt.title('Top 10 Most Frequent "snatch" Values (v1)', fontsize=14)
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Height', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Add frequency numbers above each bar
for index, value in enumerate(height_freq.values):
    plt.text(value + 0.5, index - 0.1, str(value), fontsize=10, va='center')

# Show the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Plot distributions for v1
v2['deadlift'].hist(bins=20)
plt.title('Deadlift Distribution (v1)')
plt.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Train model on v2
model_v2 = RandomForestRegressor(random_state=42)
model_v2.fit(X_train_v2, y_train_v2)

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Predict and evaluate
y_pred_v2 = model_v2.predict(X_test_v2)
rmse_v2 = np.sqrt(mean_squared_error(y_test_v2, y_pred_v2))
r2_v2 = r2_score(y_test_v2, y_pred_v2)

print("v2 RMSE:", rmse_v2)
print("v2 R²:", r2_v2)

"""# **12.Compare and comment on the accuracy/metrics of the models using v1 and v2.**

RMSE (Root Mean Squared Error) measures the average prediction error. A lower RMSE indicates better accuracy.


* v2 has a significantly lower RMSE, meaning its predictions are much closer to actual values.


* This suggests that the data cleaning and outlier removal in v2 greatly improved model precision.



R² Score indicates how well the model explains the variance in the target variable.


* v1 has a higher R², meaning it explains more variance, but this could be due to overfitting on noisy or inconsistent data.


* v2’s slightly lower R² is still strong and reflects a more generalizable model trained on cleaner data.

# **13. Use Opacus library with the dataset v2 and calculate the metrics for the new differential privacy model.**
"""

!pip install opacus torch torchvision

from sklearn.preprocessing import StandardScaler
import torch
from torch.utils.data import DataLoader, TensorDataset

# Standardize features for v2
scaler = StandardScaler()
X_train_v2_scaled = scaler.fit_transform(X_train_v2)
X_test_v2_scaled = scaler.transform(X_test_v2)

# Convert to PyTorch tensors
X_train_v2_tensor = torch.FloatTensor(X_train_v2_scaled)
y_train_v2_tensor = torch.FloatTensor(y_train_v2.values).view(-1, 1)
X_test_v2_tensor = torch.FloatTensor(X_test_v2_scaled)
y_test_v2_tensor = torch.FloatTensor(y_test_v2.values).view(-1, 1)

# Create DataLoader for v2
train_dataset_v2 = TensorDataset(X_train_v2_tensor, y_train_v2_tensor)
train_loader_v2 = DataLoader(train_dataset_v2, batch_size=32, shuffle=True)

"""**Define the Shallow Neural Network**"""

import torch.nn as nn

class ShallowNN(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 16)  # First hidden layer
        self.fc2 = nn.Linear(16, 8)          # Second hidden layer
        self.fc3 = nn.Linear(8, 1)           # Output layer
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        return self.fc3(x)

# Initialize model
input_dim = X_train_v2.shape[1]
model = ShallowNN(input_dim)

"""**Set Up DP Training with Opacus**"""

from opacus import PrivacyEngine
from torch.optim import Adam

# Define optimizer and loss
optimizer = Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# Enable DP training
privacy_engine = PrivacyEngine()

model, optimizer, train_loader_v2 = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=train_loader_v2,
    max_grad_norm=1.0,      # Gradient clipping
    noise_multiplier=0.5    # Noise for privacy
)

"""#  **14. Compute the DP ε (differential privacy budget)**


*   ε (epsilon) quantifies the privacy loss during training.

*   A smaller ε means stronger privacy, but potentially lower model accuracy.

*   A larger ε means weaker privacy, but potentially better model performance.
"""

# Training loop
epochs = 50
for epoch in range(epochs):
    model.train()
    for batch_X, batch_y in train_loader_v2:
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()

    # Print progress every 10 epochs
    if epoch % 10 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# Get privacy budget
epsilon = privacy_engine.accountant.get_epsilon(delta=1e-5)
print(f"Final Privacy Budget (ε): {epsilon:.2f}")

"""**Evaluate the Model**"""

from sklearn.metrics import mean_squared_error, r2_score

# Evaluate on test data
model.eval()
with torch.no_grad():
    y_pred_tensor = model(X_test_v2_tensor)
    y_pred = y_pred_tensor.numpy()

# Calculate metrics
rmse_dp = np.sqrt(mean_squared_error(y_test_v2, y_pred))
r2_dp = r2_score(y_test_v2, y_pred)

print(f"DP Shallow NN RMSE: {rmse_dp:.4f}")
print(f"DP Shallow NN R²: {r2_dp:.4f}")

"""# **Compare and comment on the accuracy/metrics of the non-DP and DP models using dataset v2**

The DP model introduces noise during training to protect individual data points.
Despite this, the performance degradation is minimal:


*   RMSE increased by only 0.14 units.

*   R² dropped by just 0.0011.

This shows that the DP model maintains strong predictive power while offering privacy guarantees.

Both models perform very well.The non-DP model is slightly more accurate, but the DP model is nearly as good and provides privacy protection. If privacy is a concern (e.g., sensitive athlete data), the DP model is a highly viable choice with minimal trade-off in accuracy.
"""

# Reset model and optimizer for non-DP training
model_non_dp = ShallowNN(input_dim)
optimizer_non_dp = Adam(model_non_dp.parameters(), lr=0.001)

# Train without DP
for epoch in range(epochs):
    model_non_dp.train()
    for batch_X, batch_y in train_loader_v2:
        optimizer_non_dp.zero_grad()
        outputs = model_non_dp(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer_non_dp.step()

# Evaluate non-DP model
model_non_dp.eval()
with torch.no_grad():
    y_pred_non_dp = model_non_dp(X_test_v2_tensor).numpy()

rmse_non_dp = np.sqrt(mean_squared_error(y_test_v2, y_pred_non_dp))
r2_non_dp = r2_score(y_test_v2, y_pred_non_dp)

print(f"Non-DP Shallow NN RMSE: {rmse_non_dp:.4f}")
print(f"Non-DP Shallow NN R²: {r2_non_dp:.4f}")

import matplotlib.pyplot as plt
import numpy as np

# Metrics for comparison
metrics = {
    'Model': ['Non-DP Shallow NN', 'DP Shallow NN'],
    'RMSE': [rmse_non_dp, rmse_dp],
    'R²': [r2_non_dp, r2_dp]
}

x = np.arange(len(metrics['Model']))
width = 0.35

fig, ax1 = plt.subplots(figsize=(10, 6))

# Plot RMSE
bars1 = ax1.bar(x - width/2, metrics['RMSE'], width, label='RMSE', color='tab:blue')
ax1.set_ylabel('RMSE', color='tab:blue')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Plot R²
ax2 = ax1.twinx()
bars2 = ax2.bar(x + width/2, metrics['R²'], width, label='R²', color='tab:orange')
ax2.set_ylabel('R²', color='tab:orange')
ax2.tick_params(axis='y', labelcolor='tab:orange')

ax1.set_xticks(x)
ax1.set_xticklabels(metrics['Model'])
plt.title('DP vs Non-DP Shallow Neural Network Performance on v2 Dataset')
fig.legend(loc="upper right", bbox_to_anchor=(1, 1), bbox_transform=ax1.transAxes)
plt.tight_layout()
plt.show()

# Get feature importance by looking at first layer weights
weights = model.fc1.weight.detach().numpy().mean(axis=0)
feature_importance = pd.DataFrame({
    'Feature': X_train_v2.columns,
    'Importance': np.abs(weights)
}).sort_values('Importance', ascending=False)

print("\nFeature Importance:")
print(feature_importance)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['Feature'], feature_importance['Importance'])
plt.title('Feature Importance from First Layer Weights')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()